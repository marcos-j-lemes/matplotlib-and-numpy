{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "7e43de71-1709-4ad9-8663-c0bfb07778b6",
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Módulo de funções de ativação para redes neurais.\n",
        "\n",
        "Cada função de ativação tem:\n",
        "- forward: calcula a ativação\n",
        "- derivada: usada no backpropagation (veremos depois)\n",
        "\"\"\"\n",
        "\n",
        "class Ativacao:\n",
        "    \"\"\"\"Classe base para funções de ativação. \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Aplica a função de ativação \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def derivada(self, x):\n",
        "        \"\"\"Calcula a derivada (para backpropagation) \"\"\"\n",
        "        raise NotImplementedError\n"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "editable": true,
        "id": "7e43de71-1709-4ad9-8663-c0bfb07778b6"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "id": "2201913f-e7e3-441a-b9ee-aab5be5877b8",
      "cell_type": "code",
      "source": [
        "# === Funções de ativação\n",
        "\n",
        "class Degrau(Ativacao):\n",
        "    \"\"\"\n",
        "    Função Degrau (Step Function).\n",
        "    Retorna 1 se x >= limiar, senão 0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, limiar=1.0):\n",
        "        self.limiar = limiar\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 1 if x >= self.limiar else 0\n",
        "\n",
        "    def derivada(self, x):\n",
        "        # Degrau não é diferenciável, mas podemos retornar 0\n",
        "        return 0\n",
        "\n",
        "class Sigmoid(Ativacao):\n",
        "    \"\"\"\n",
        "    Função Sigmoid (Logística).\n",
        "    Mapeia valores para range (0, 1).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def derivada(self, x):\n",
        "        s = self.forward(x)\n",
        "        return s * (1 - s)\n",
        "\n",
        "class ReLU(Ativacao):\n",
        "    \"\"\"\n",
        "    Rectified Linear Unit.\n",
        "    Retorna max(0, x).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return max(0, x)\n",
        "\n",
        "    def derivada(self, x):\n",
        "        return 1 if 0 >= 0 else 0\n",
        "\n",
        "class Tanh(Ativacao):\n",
        "    \"\"\"\n",
        "    Tangente Hiperbólica.\n",
        "    Mapeia valores para range (-1, 1).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def derivada(self, x):\n",
        "        return 1 - np.tanh(x)**2\n",
        "\n",
        "class Linear(Ativacao):\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "    def derivada(self, x):\n",
        "        s = self.foward(x)\n",
        "        return s\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "2201913f-e7e3-441a-b9ee-aab5be5877b8"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "id": "7d08b9b9-49a5-42b8-9e4c-8fdf0bc3e7ce",
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementação de um neurônio artificial\n",
        "\"\"\"\n",
        "\n",
        "# from activations import Ativacao, Degrau\n",
        "\n",
        "class Neuronio:\n",
        "    \"\"\"\n",
        "    Um neurônio artificial com aprendizado supervisionado.\n",
        "\n",
        "    Attributes:\n",
        "        pesos (np.ndarray): Pesos sinápticos\n",
        "        bias (float): Termo de viés\n",
        "        taxa_aprendizado (float): Taxa de aprendizado\n",
        "        ativacao (Ativacao): Função de ativação\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_entradas, taxa_aprendizado=0.1, ativacao=None):\n",
        "\n",
        "        \"\"\"\n",
        "        Inicializa o neurônio.\n",
        "\n",
        "        Args:\n",
        "            num_entradas (int): Número de entradas\n",
        "            taxa_aprendizado (float): Taxa de aprendizado\n",
        "            ativacao (Ativacao): Função de ativação (padrão: Degrau)\n",
        "        \"\"\"\n",
        "        self.pesos = np.random.rand(num_entradas)\n",
        "        self.bias = 0.0\n",
        "        self.taxa_aprendizado = taxa_aprendizado\n",
        "\n",
        "        # Se não passar ativação, usa Degrau por padrão\n",
        "        self.ativacao = ativacao if ativacao is not None else Degrau()\n",
        "\n",
        "\n",
        "    def forward(self, entrada):\n",
        "        \"\"\"\n",
        "        Propagação para frente.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada\n",
        "\n",
        "        Returns:\n",
        "            tuple: (saida_bruta, saida_ativada)\n",
        "        \"\"\"\n",
        "\n",
        "        # Combinação linear\n",
        "        saida_bruta = np.dot(entrada, self.pesos) + self.bias\n",
        "\n",
        "        # Aplica ativação (agora vem do objeto de ativação)\n",
        "        saida_ativada = self.ativacao.forward(saida_bruta)\n",
        "\n",
        "        return saida_bruta, saida_ativada\n",
        "\n",
        "    def treinar(self, entrada, esperado):\n",
        "        \"\"\"\n",
        "        Treina o neurônio com um exemplo.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada\n",
        "            esperado: Saída esperada\n",
        "\n",
        "        Returns:\n",
        "            tuple: (saida, erro)\n",
        "        \"\"\"\n",
        "        saida_bruta, saida = self.forward(entrada)\n",
        "        erro = esperado - saida\n",
        "\n",
        "        # Atualiza pesos\n",
        "        self.pesos += self.taxa_aprendizado * erro * np.array(entrada)\n",
        "        self.bias += self.taxa_aprendizado * erro\n",
        "\n",
        "        return saida, erro\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Representação em string do neurônio.\"\"\"\n",
        "        return f\"Neuronio(entradas={len(self.pesos)}, ativacao={self.ativacao.__class__.__name__})\"\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "7d08b9b9-49a5-42b8-9e4c-8fdf0bc3e7ce"
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "676eeeb5-bae6-4938-9204-e57e6191a8e7",
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementação de uma camada de neurônios.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Camada:\n",
        "    \"\"\"\n",
        "    Uma camada (layer) de neurônios.\n",
        "\n",
        "    Todos os neurônios da camada:\n",
        "    - Recebem a mesma entrada\n",
        "    - Podem ter ativações diferentes (ou mesma)\n",
        "    - Produzem um vetor de saídas\n",
        "\n",
        "    Attributes:\n",
        "        neuronios (list): Lista de objetos Neuronio\n",
        "        num_neuronios (int): Quantidade de neurônios na camada\n",
        "        num_entradas (int): Número de entradas que cada neurônio recebe\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_entradas, num_neuronios, taxa_aprendizado=0.1, ativacao=None):\n",
        "        \"\"\"\n",
        "        Inicializa a camada.\n",
        "\n",
        "        Args:\n",
        "            num_entradas (int): Número de entradas para cada neurônio\n",
        "            num_neuronios (int): Quantidade de neurônios na camada\n",
        "            taxa_aprendizado (float): Taxa de aprendizado\n",
        "            ativacao (Ativacao): Função de ativação (padrão: Degrau)\n",
        "        \"\"\"\n",
        "        self.num_neuronios = num_neuronios\n",
        "        self.num_entradas = num_entradas\n",
        "\n",
        "        # Cria uma lista de neurônios\n",
        "        self.neuronios = []\n",
        "        for _ in range(num_neuronios):\n",
        "            neuronio = Neuronio(\n",
        "                num_entradas=num_entradas,\n",
        "                taxa_aprendizado=taxa_aprendizado,\n",
        "                ativacao=ativacao if ativacao is not None else Degrau()\n",
        "            )\n",
        "            self.neuronios.append(neuronio)\n",
        "\n",
        "    def forward(self, entrada):\n",
        "        \"\"\"\n",
        "        Propagação para frente através da camada.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada (mesmo para todos os neurônios)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (saidas_brutas, saidas_ativadas)\n",
        "                - saidas_brutas: lista com saídas antes da ativação\n",
        "                - saidas_ativadas: lista com saídas após ativação\n",
        "        \"\"\"\n",
        "        saidas_brutas = []\n",
        "        saidas_ativadas = []\n",
        "\n",
        "        # Cada neurônio processa a mesma entrada\n",
        "        for neuronio in self.neuronios:\n",
        "            bruta, ativada = neuronio.forward(entrada)\n",
        "            saidas_brutas.append(bruta)\n",
        "            saidas_ativadas.append(ativada)\n",
        "\n",
        "        return np.array(saidas_brutas), np.array(saidas_ativadas)\n",
        "\n",
        "    def treinar(self, entrada, esperados):\n",
        "        \"\"\"\n",
        "        Treina todos os neurônios da camada.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada\n",
        "            esperados: Lista de saídas esperadas (uma para cada neurônio)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (saidas, erros)\n",
        "        \"\"\"\n",
        "        if len(esperados) != self.num_neuronios:\n",
        "            raise ValueError(\n",
        "                f\"esperados deve ter {self.num_neuronios} valores, \"\n",
        "                f\"mas recebeu {len(esperados)}\"\n",
        "            )\n",
        "\n",
        "        saidas = []\n",
        "        erros = []\n",
        "\n",
        "        # Treina cada neurônio com sua saída esperada\n",
        "        for neuronio, esperado in zip(self.neuronios, esperados):\n",
        "            saida, erro = neuronio.treinar(entrada, esperado)\n",
        "            saidas.append(saida)\n",
        "            erros.append(erro)\n",
        "\n",
        "        return np.array(saidas), np.array(erros)\n",
        "\n",
        "    def get_pesos(self):\n",
        "        \"\"\"\n",
        "        Retorna os pesos de todos os neurônios como matriz.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Matriz de pesos (num_neuronios x num_entradas)\n",
        "        \"\"\"\n",
        "        pesos_matriz = []\n",
        "        for neuronio in self.neuronios:\n",
        "            pesos_matriz.append(neuronio.pesos)\n",
        "        return np.array(pesos_matriz)\n",
        "\n",
        "    def get_bias(self):\n",
        "        \"\"\"\n",
        "        Retorna os bias de todos os neurônios.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Vetor de bias\n",
        "        \"\"\"\n",
        "        return np.array([neuronio.bias for neuronio in self.neuronios])\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Representação em string da camada.\"\"\"\n",
        "        ativacao_nome = self.neuronios[0].ativacao.__class__.__name__\n",
        "        return (\n",
        "            f\"Camada(neuronios={self.num_neuronios}, \"\n",
        "            f\"entradas={self.num_entradas}, \"\n",
        "            f\"ativacao={ativacao_nome})\"\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Retorna o número de neurônios.\"\"\"\n",
        "        return self.num_neuronios\n",
        "\n",
        "\n",
        "class CamadaVetorizada:\n",
        "    \"\"\"\n",
        "    Versão OTIMIZADA da camada usando operações vetorizadas.\n",
        "\n",
        "    Muito mais rápida que criar neurônios individuais!\n",
        "    Essa é a abordagem usada em bibliotecas profissionais.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_entradas, num_neuronios, taxa_aprendizado=0.1, ativacao=None):\n",
        "        \"\"\"\n",
        "        Inicializa a camada vetorizada.\n",
        "\n",
        "        Args:\n",
        "            num_entradas (int): Dimensão da entrada\n",
        "            num_neuronios (int): Número de neurônios (dimensão da saída)\n",
        "            taxa_aprendizado (float): Taxa de aprendizado\n",
        "            ativacao (Ativacao): Função de ativação\n",
        "        \"\"\"\n",
        "        self.num_neuronios = num_neuronios\n",
        "        self.num_entradas = num_entradas\n",
        "        self.taxa_aprendizado = taxa_aprendizado\n",
        "        self.ativacao = ativacao if ativacao is not None else Degrau()\n",
        "\n",
        "        # Matriz de pesos: (num_neuronios x num_entradas)\n",
        "        # Cada LINHA é um neurônio\n",
        "        self.pesos = np.random.rand(num_neuronios, num_entradas)\n",
        "\n",
        "        # Vetor de bias: (num_neuronios,)\n",
        "        self.bias = np.zeros(num_neuronios)\n",
        "\n",
        "    def forward(self, entrada):\n",
        "        \"\"\"\n",
        "        Propagação vetorizada (MUITO mais rápida!).\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada (num_entradas,)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (saidas_brutas, saidas_ativadas)\n",
        "        \"\"\"\n",
        "        # Multiplicação matricial: (num_neuronios x num_entradas) @ (num_entradas,)\n",
        "        # Resultado: (num_neuronios,)\n",
        "        saidas_brutas = self.pesos @ entrada + self.bias\n",
        "\n",
        "        # Aplica ativação em cada elemento\n",
        "        saidas_ativadas = np.array([\n",
        "            self.ativacao.forward(x) for x in saidas_brutas\n",
        "        ])\n",
        "\n",
        "        return saidas_brutas, saidas_ativadas\n",
        "\n",
        "    def treinar(self, entrada, esperados):\n",
        "        \"\"\"\n",
        "        Treinamento vetorizado.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada\n",
        "            esperados: Vetor de saídas esperadas\n",
        "\n",
        "        Returns:\n",
        "            tuple: (saidas, erros)\n",
        "        \"\"\"\n",
        "        saidas_brutas, saidas = self.forward(entrada)\n",
        "        erros = esperados - saidas\n",
        "\n",
        "        # Atualização vetorizada dos pesos\n",
        "        # Cada linha (neurônio) é atualizada: peso += taxa * erro * entrada\n",
        "        entrada_array = np.array(entrada)\n",
        "        for i in range(self.num_neuronios):\n",
        "            self.pesos[i] += self.taxa_aprendizado * erros[i] * entrada_array\n",
        "            self.bias[i] += self.taxa_aprendizado * erros[i]\n",
        "\n",
        "        return saidas, erros\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"CamadaVetorizada(neuronios={self.num_neuronios}, \"\n",
        "            f\"entradas={self.num_entradas}, \"\n",
        "            f\"ativacao={self.ativacao.__class__.__name__})\"\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "editable": true,
        "id": "676eeeb5-bae6-4938-9204-e57e6191a8e7"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "id": "c556ce43-6e35-4532-b700-1423c4118b48",
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Testes para a classe Camada.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTE 1: Camada com 3 neurônios\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cria uma camada: 10 entradas → 3 neurônios\n",
        "camada = Camada(\n",
        "    num_entradas=10,\n",
        "    num_neuronios=3,\n",
        "    taxa_aprendizado=0.1,\n",
        "    ativacao=Sigmoid()\n",
        ")\n",
        "\n",
        "print(f\"\\n{camada}\")\n",
        "print(f\"Número de neurônios: {len(camada)}\")\n",
        "\n",
        "# Entrada de teste\n",
        "entrada = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "# Saídas esperadas para cada neurônio\n",
        "esperados = [1, 0, 1]  # Neurônio 1: quer 1, Neurônio 2: quer 0, Neurônio 3: quer 1\n",
        "\n",
        "print(\"\\n--- Treinamento ---\")\n",
        "for epoca in range(10):\n",
        "    saidas, erros = camada.treinar(entrada, esperados)\n",
        "    print(f\"Época {epoca} | saídas={saidas} | erros={erros}\")\n",
        "\n",
        "# Testa após treinamento\n",
        "print(\"\\n--- Teste Final ---\")\n",
        "_, saidas_finais = camada.forward(entrada)\n",
        "print(f\"Entrada: {entrada}\")\n",
        "print(f\"Saídas: {saidas_finais}\")\n",
        "print(f\"Esperado: {esperados}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TESTE 2: Comparando Camada vs CamadaVetorizada\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Mesma configuração para ambas\n",
        "entrada = np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "esperados = np.array([1, 0, 1])\n",
        "\n",
        "# Camada normal\n",
        "camada_normal = Camada(10, 3, taxa_aprendizado=0.1, ativacao=Sigmoid())\n",
        "\n",
        "# Camada vetorizada\n",
        "camada_vet = CamadaVetorizada(10, 3, taxa_aprendizado=0.1, ativacao=Sigmoid())\n",
        "\n",
        "print(\"\\nTreinando ambas por 100 épocas...\")\n",
        "\n",
        "# Treina camada normal\n",
        "for _ in range(100):\n",
        "    camada_normal.treinar(entrada, esperados)\n",
        "\n",
        "# Treina camada vetorizada\n",
        "for _ in range(100):\n",
        "    camada_vet.treinar(entrada, esperados)\n",
        "\n",
        "# Compara resultados\n",
        "_, saidas_normal = camada_normal.forward(entrada)\n",
        "_, saidas_vet = camada_vet.forward(entrada)\n",
        "\n",
        "print(f\"\\nCamada Normal: {saidas_normal}\")\n",
        "print(f\"Camada Vetorizada: {saidas_vet}\")\n",
        "print(f\"Esperado: {esperados}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TESTE 3: Visualizando Pesos da Camada\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "camada = Camada(5, 2, ativacao=ReLU())\n",
        "\n",
        "print(f\"\\nPesos iniciais:\")\n",
        "print(camada.get_pesos())\n",
        "print(f\"\\nBias iniciais:\")\n",
        "print(camada.get_bias())\n",
        "\n",
        "# Treina um pouco\n",
        "entrada = [1, 0, 1, 0, 1]\n",
        "esperados = [1, 0]\n",
        "\n",
        "for _ in range(50):\n",
        "    camada.treinar(entrada, esperados)\n",
        "\n",
        "print(f\"\\nPesos após treinamento:\")\n",
        "print(camada.get_pesos())\n",
        "print(f\"\\nBias após treinamento:\")\n",
        "print(camada.get_bias())"
      ],
      "metadata": {
        "trusted": true,
        "tags": [],
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c556ce43-6e35-4532-b700-1423c4118b48",
        "outputId": "1c10d8b9-3b52-4f24-b2f6-86c8f76812da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TESTE 1: Camada com 3 neurônios\n",
            "============================================================\n",
            "\n",
            "Camada(neuronios=3, entradas=10, ativacao=Sigmoid)\n",
            "Número de neurônios: 3\n",
            "\n",
            "--- Treinamento ---\n",
            "Época 0 | saídas=[0.53505645 0.58097709 0.62260904] | erros=[ 0.46494355 -0.58097709  0.37739096]\n",
            "Época 1 | saídas=[0.55809764 0.55245387 0.64017305] | erros=[ 0.44190236 -0.55245387  0.35982695]\n",
            "Época 2 | saídas=[0.57976906 0.52500401 0.65657782] | erros=[ 0.42023094 -0.52500401  0.34342218]\n",
            "Época 3 | saídas=[0.60009756 0.49877469 0.67189428] | erros=[ 0.39990244 -0.49877469  0.32810572]\n",
            "Época 4 | saídas=[0.61912881 0.47385981 0.68619418] | erros=[ 0.38087119 -0.47385981  0.31380582]\n",
            "Época 5 | saídas=[0.63692127 0.45030755 0.69954822] | erros=[ 0.36307873 -0.45030755  0.30045178]\n",
            "Época 6 | saídas=[0.6535413  0.42812881 0.71202468] | erros=[ 0.3464587  -0.42812881  0.28797532]\n",
            "Época 7 | saídas=[0.66905938 0.40730554 0.72368863] | erros=[ 0.33094062 -0.40730554  0.27631137]\n",
            "Época 8 | saídas=[0.68354728 0.38779828 0.73460139] | erros=[ 0.31645272 -0.38779828  0.26539861]\n",
            "Época 9 | saídas=[0.697076   0.36955271 0.74482028] | erros=[ 0.302924   -0.36955271  0.25517972]\n",
            "\n",
            "--- Teste Final ---\n",
            "Entrada: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Saídas: [0.70971439 0.35250489 0.75439857]\n",
            "Esperado: [1, 0, 1]\n",
            "\n",
            "============================================================\n",
            "TESTE 2: Comparando Camada vs CamadaVetorizada\n",
            "============================================================\n",
            "\n",
            "Treinando ambas por 100 épocas...\n",
            "\n",
            "Camada Normal: [0.95070192 0.05376047 0.954167  ]\n",
            "Camada Vetorizada: [0.95052714 0.05548777 0.95170668]\n",
            "Esperado: [1 0 1]\n",
            "\n",
            "============================================================\n",
            "TESTE 3: Visualizando Pesos da Camada\n",
            "============================================================\n",
            "\n",
            "Pesos iniciais:\n",
            "[[0.55358838 0.03251643 0.84854318 0.40668751 0.83408331]\n",
            " [0.1740563  0.9113751  0.578381   0.93365978 0.15394757]]\n",
            "\n",
            "Bias iniciais:\n",
            "[0. 0.]\n",
            "\n",
            "Pesos após treinamento:\n",
            "[[ 0.24453466  0.03251643  0.53948946  0.40668751  0.52502959]\n",
            " [-0.05253992  0.9113751   0.35178478  0.93365978 -0.07264864]]\n",
            "\n",
            "Bias após treinamento:\n",
            "[-0.30905372 -0.22659622]\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d821540"
      },
      "source": [
        "### Visualização do TESTE 1: Parâmetros da Camada (Antes e Depois do Treinamento)"
      ],
      "id": "8d821540"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implementação de uma rede neural feedforward.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class RedeNeural:\n",
        "    \"\"\"\n",
        "    Rede neural feedforward (camadas totalmente conectadas).\n",
        "\n",
        "    A saída de uma camada vira entrada da próxima.\n",
        "\n",
        "    Attributes:\n",
        "        camadas (list): Lista de objetos CamadaVetorizada\n",
        "        historico (dict): Histórico de treinamento (loss, acurácia)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, arquitetura, taxa_aprendizado=0.1, ativacao=None):\n",
        "        \"\"\"\n",
        "        Inicializa a rede neural.\n",
        "\n",
        "        Args:\n",
        "            arquitetura (list): Lista com número de neurônios por camada\n",
        "                Exemplo: [10, 5, 3, 2] significa:\n",
        "                - Entrada: 10 features\n",
        "                - Hidden 1: 5 neurônios\n",
        "                - Hidden 2: 3 neurônios\n",
        "                - Saída: 2 neurônios\n",
        "            taxa_aprendizado (float): Taxa de aprendizado\n",
        "            ativacao (Ativacao): Função de ativação (padrão: Sigmoid)\n",
        "        \"\"\"\n",
        "        if len(arquitetura) < 2:\n",
        "            raise ValueError(\"Arquitetura deve ter pelo menos 2 camadas (entrada + saída)\")\n",
        "\n",
        "        self.arquitetura = arquitetura\n",
        "        self.camadas = []\n",
        "        self.historico = {\n",
        "            'loss': [],\n",
        "            'acuracia': []\n",
        "        }\n",
        "\n",
        "        # Cria as camadas\n",
        "        for i in range(len(arquitetura) - 1):\n",
        "            num_entradas = arquitetura[i]\n",
        "            num_neuronios = arquitetura[i + 1]\n",
        "\n",
        "            camada = CamadaVetorizada(\n",
        "                num_entradas=num_entradas,\n",
        "                num_neuronios=num_neuronios,\n",
        "                taxa_aprendizado=taxa_aprendizado,\n",
        "                ativacao=ativacao if ativacao is not None else Sigmoid()\n",
        "            )\n",
        "            self.camadas.append(camada)\n",
        "\n",
        "    def forward(self, entrada):\n",
        "        \"\"\"\n",
        "        Propagação para frente através de todas as camadas.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor/matriz de entrada\n",
        "\n",
        "        Returns:\n",
        "            tuple: (todas_ativacoes, saida_final)\n",
        "                - todas_ativacoes: lista com saídas de cada camada\n",
        "                - saida_final: saída da última camada\n",
        "        \"\"\"\n",
        "        ativacoes = [np.array(entrada)]  # Começa com a entrada\n",
        "\n",
        "        # Propaga através de cada camada\n",
        "        for camada in self.camadas:\n",
        "            _, saida_ativada = camada.forward(ativacoes[-1])\n",
        "            ativacoes.append(saida_ativada)\n",
        "\n",
        "        return ativacoes, ativacoes[-1]\n",
        "\n",
        "    def treinar_epoca(self, entradas, esperados):\n",
        "        \"\"\"\n",
        "        Treina a rede por uma época (todos os exemplos).\n",
        "\n",
        "        Args:\n",
        "            entradas (list): Lista de vetores de entrada\n",
        "            esperados (list): Lista de vetores de saída esperada\n",
        "\n",
        "        Returns:\n",
        "            dict: Métricas da época (loss médio, acurácia)\n",
        "        \"\"\"\n",
        "        total_loss = 0\n",
        "        acertos = 0\n",
        "\n",
        "        for entrada, esperado in zip(entradas, esperados):\n",
        "            # Forward pass\n",
        "            todas_ativacoes, saida = self.forward(entrada)\n",
        "\n",
        "            # Calcula erro/loss\n",
        "            erro = np.array(esperado) - saida\n",
        "            loss = np.mean(erro ** 2)  # MSE (Mean Squared Error)\n",
        "            total_loss += loss\n",
        "\n",
        "            # Calcula acurácia (para classificação)\n",
        "            predicao = np.argmax(saida) if len(saida) > 1 else round(saida[0])\n",
        "            alvo = np.argmax(esperado) if len(esperado) > 1 else esperado[0]\n",
        "            if predicao == alvo:\n",
        "                acertos += 1\n",
        "\n",
        "            # Backward pass (simplificado - só última camada por enquanto)\n",
        "            self._treinar_ultima_camada(todas_ativacoes[-2], esperado)\n",
        "\n",
        "        # Métricas da época\n",
        "        num_exemplos = len(entradas)\n",
        "        metricas = {\n",
        "            'loss': total_loss / num_exemplos,\n",
        "            'acuracia': acertos / num_exemplos\n",
        "        }\n",
        "\n",
        "        return metricas\n",
        "\n",
        "    def _treinar_ultima_camada(self, entrada_camada, esperado):\n",
        "        \"\"\"\n",
        "        Treina apenas a última camada (simplificação).\n",
        "\n",
        "        Args:\n",
        "            entrada_camada: Entrada que chegou na última camada\n",
        "            esperado: Saída esperada\n",
        "        \"\"\"\n",
        "        self.camadas[-1].treinar(entrada_camada, esperado)\n",
        "\n",
        "    def treinar(self, entradas, esperados, num_epocas=100, verbose=True):\n",
        "        \"\"\"\n",
        "        Treina a rede por múltiplas épocas.\n",
        "\n",
        "        Args:\n",
        "            entradas (list): Conjunto de entradas\n",
        "            esperados (list): Conjunto de saídas esperadas\n",
        "            num_epocas (int): Número de épocas\n",
        "            verbose (bool): Mostrar progresso\n",
        "\n",
        "        Returns:\n",
        "            dict: Histórico completo de treinamento\n",
        "        \"\"\"\n",
        "        for epoca in range(num_epocas):\n",
        "            metricas = self.treinar_epoca(entradas, esperados)\n",
        "\n",
        "            # Salva no histórico\n",
        "            self.historico['loss'].append(metricas['loss'])\n",
        "            self.historico['acuracia'].append(metricas['acuracia'])\n",
        "\n",
        "            # Mostra progresso\n",
        "            if verbose and (epoca % 10 == 0 or epoca == num_epocas - 1):\n",
        "                print(f\"Época {epoca:3d} | \"\n",
        "                      f\"Loss: {metricas['loss']:.4f} | \"\n",
        "                      f\"Acurácia: {metricas['acuracia']:.2%}\")\n",
        "\n",
        "        return self.historico\n",
        "\n",
        "    def prever(self, entrada):\n",
        "        \"\"\"\n",
        "        Faz predição para uma entrada.\n",
        "\n",
        "        Args:\n",
        "            entrada: Vetor de entrada\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Saída da rede\n",
        "        \"\"\"\n",
        "        _, saida = self.forward(entrada)\n",
        "        return saida\n",
        "\n",
        "    def __repr__(self):\n",
        "        camadas_str = \" → \".join(map(str, self.arquitetura))\n",
        "        return f\"RedeNeural({camadas_str})\""
      ],
      "metadata": {
        "id": "uAjfXWBdW6DH"
      },
      "id": "uAjfXWBdW6DH",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Testes completos para a rede neural com validação de aprendizado.\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TESTE 1: Rede Neural para Porta Lógica OR\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Dataset: Porta OR\n",
        "# 0 OR 0 = 0\n",
        "# 0 OR 1 = 1\n",
        "# 1 OR 0 = 1\n",
        "# 1 OR 1 = 1\n",
        "\n",
        "entradas_treino = [\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "]\n",
        "\n",
        "saidas_treino = [\n",
        "    [0],  # 0 OR 0 = 0\n",
        "    [1],  # 0 OR 1 = 1\n",
        "    [1],  # 1 OR 0 = 1\n",
        "    [1]   # 1 OR 1 = 1\n",
        "]\n",
        "\n",
        "# Cria rede: 2 entradas → 3 neurônios hidden → 1 saída\n",
        "rede = RedeNeural(\n",
        "    arquitetura=[2, 3, 1],\n",
        "    taxa_aprendizado=0.5,\n",
        "    ativacao=Sigmoid()\n",
        ")\n",
        "\n",
        "print(f\"\\n{rede}\")\n",
        "print(f\"Número de camadas: {len(rede.camadas)}\")\n",
        "\n",
        "# Treina\n",
        "print(\"\\n--- Treinamento ---\")\n",
        "rede.treinar(entradas_treino, saidas_treino, num_epocas=100, verbose=True)\n",
        "\n",
        "# Testa com dados de treinamento\n",
        "print(\"\\n--- Validação com Dados de Treinamento ---\")\n",
        "for entrada, esperado in zip(entradas_treino, saidas_treino):\n",
        "    predicao = rede.prever(entrada)\n",
        "    print(f\"Entrada: {entrada} | Esperado: {esperado[0]} | \"\n",
        "          f\"Predição: {predicao[0]:.4f} | \"\n",
        "          f\"Correto: {'✓' if abs(predicao[0] - esperado[0]) < 0.5 else '✗'}\")\n",
        "\n",
        "# Testa com novas entradas (mesmas, mas verificando consistência)\n",
        "print(\"\\n--- Teste de Consistência (rodando predições novamente) ---\")\n",
        "for entrada, esperado in zip(entradas_treino, saidas_treino):\n",
        "    predicao = rede.prever(entrada)\n",
        "    print(f\"Entrada: {entrada} | Predição: {predicao[0]:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TESTE 2: Rede Neural para Porta Lógica XOR (mais difícil!)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Dataset: Porta XOR (não é linearmente separável!)\n",
        "# 0 XOR 0 = 0\n",
        "# 0 XOR 1 = 1\n",
        "# 1 XOR 0 = 1\n",
        "# 1 XOR 1 = 0\n",
        "\n",
        "entradas_xor = [\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "]\n",
        "\n",
        "saidas_xor = [\n",
        "    [0],  # 0 XOR 0 = 0\n",
        "    [1],  # 0 XOR 1 = 1\n",
        "    [1],  # 1 XOR 0 = 1\n",
        "    [0]   # 1 XOR 1 = 0\n",
        "]\n",
        "\n",
        "# Rede maior para XOR\n",
        "rede_xor = RedeNeural(\n",
        "    arquitetura=[2, 4, 1],  # Precisa de hidden layer maior\n",
        "    taxa_aprendizado=0.3,\n",
        "    ativacao=Sigmoid()\n",
        ")\n",
        "\n",
        "print(f\"\\n{rede_xor}\")\n",
        "\n",
        "print(\"\\n--- Treinamento ---\")\n",
        "rede_xor.treinar(entradas_xor, saidas_xor, num_epocas=500, verbose=True)\n",
        "\n",
        "print(\"\\n--- Validação XOR ---\")\n",
        "for entrada, esperado in zip(entradas_xor, saidas_xor):\n",
        "    predicao = rede_xor.prever(entrada)\n",
        "    resultado = \"✓\" if abs(predicao[0] - esperado[0]) < 0.5 else \"✗\"\n",
        "    print(f\"Entrada: {entrada} | Esperado: {esperado[0]} | \"\n",
        "          f\"Predição: {predicao[0]:.4f} | {resultado}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TESTE 3: Classificação Multi-Classe (3 classes)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Dataset sintético: 3 padrões diferentes\n",
        "# Padrão A: [1, 0, 0, ...] → Classe 0\n",
        "# Padrão B: [0, 1, 0, ...] → Classe 1\n",
        "# Padrão C: [0, 0, 1, ...] → Classe 2\n",
        "\n",
        "entradas_multi = [\n",
        "    # Classe 0\n",
        "    [1, 0, 0, 0, 0],\n",
        "    [1, 1, 0, 0, 0],\n",
        "    [1, 0, 1, 0, 0],\n",
        "    # Classe 1\n",
        "    [0, 1, 0, 0, 0],\n",
        "    [0, 1, 1, 0, 0],\n",
        "    [0, 1, 0, 1, 0],\n",
        "    # Classe 2\n",
        "    [0, 0, 1, 0, 0],\n",
        "    [0, 0, 1, 1, 0],\n",
        "    [0, 0, 1, 0, 1],\n",
        "]\n",
        "\n",
        "saidas_multi = [\n",
        "    # Classe 0 (one-hot encoding)\n",
        "    [1, 0, 0],\n",
        "    [1, 0, 0],\n",
        "    [1, 0, 0],\n",
        "    # Classe 1\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    # Classe 2\n",
        "    [0, 0, 1],\n",
        "    [0, 0, 1],\n",
        "    [0, 0, 1],\n",
        "]\n",
        "\n",
        "# Rede: 5 entradas → 8 hidden → 3 saídas\n",
        "rede_multi = RedeNeural(\n",
        "    arquitetura=[5, 8, 3],\n",
        "    taxa_aprendizado=0.2,\n",
        "    ativacao=Sigmoid()\n",
        ")\n",
        "\n",
        "print(f\"\\n{rede_multi}\")\n",
        "\n",
        "print(\"\\n--- Treinamento ---\")\n",
        "rede_multi.treinar(entradas_multi, saidas_multi, num_epocas=200, verbose=True)\n",
        "\n",
        "print(\"\\n--- Validação Multi-Classe ---\")\n",
        "for i, (entrada, esperado) in enumerate(zip(entradas_multi, saidas_multi)):\n",
        "    predicao = rede_multi.prever(entrada)\n",
        "    classe_esperada = np.argmax(esperado)\n",
        "    classe_predita = np.argmax(predicao)\n",
        "    correto = \"✓\" if classe_esperada == classe_predita else \"✗\"\n",
        "\n",
        "    print(f\"Exemplo {i+1} | Entrada: {entrada}\")\n",
        "    print(f\"  Esperado: Classe {classe_esperada} {esperado}\")\n",
        "    print(f\"  Predito:  Classe {classe_predita} {predicao.round(3)} {correto}\")\n",
        "\n",
        "# Testa com dados NOVOS (variações)\n",
        "print(\"\\n--- Teste com Dados NOVOS (Generalização) ---\")\n",
        "entradas_teste = [\n",
        "    [1, 1, 1, 0, 0],  # Deve prever Classe 0 (começa com 1)\n",
        "    [0, 1, 1, 1, 0],  # Deve prever Classe 1 (tem 1 na pos 1)\n",
        "    [0, 0, 1, 1, 1],  # Deve prever Classe 2 (tem 1 na pos 2)\n",
        "]\n",
        "\n",
        "for i, entrada in enumerate(entradas_teste):\n",
        "    predicao = rede_multi.prever(entrada)\n",
        "    classe_predita = np.argmax(predicao)\n",
        "    print(f\"Entrada NOVA {i+1}: {entrada}\")\n",
        "    print(f\"  Predição: Classe {classe_predita} {predicao.round(3)}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TESTE 4: Visualização do Histórico de Treinamento\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n--- Evolução do Loss (OR) ---\")\n",
        "historico_or = rede.historico\n",
        "for i in [0, 25, 50, 75, 99]:\n",
        "    if i < len(historico_or['loss']):\n",
        "        print(f\"Época {i:3d}: Loss = {historico_or['loss'][i]:.6f}\")\n",
        "\n",
        "print(\"\\n--- Evolução da Acurácia (XOR) ---\")\n",
        "historico_xor = rede_xor.historico\n",
        "epocas_mostrar = [0, 100, 200, 300, 400, 499]\n",
        "for i in epocas_mostrar:\n",
        "    if i < len(historico_xor['acuracia']):\n",
        "        print(f\"Época {i:3d}: Acurácia = {historico_xor['acuracia'][i]:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRlJv8uLXAXg",
        "outputId": "03f72314-f4ef-4233-bccf-55aa2ddd6d22"
      },
      "id": "JRlJv8uLXAXg",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TESTE 1: Rede Neural para Porta Lógica OR\n",
            "======================================================================\n",
            "\n",
            "RedeNeural(2 → 3 → 1)\n",
            "Número de camadas: 2\n",
            "\n",
            "--- Treinamento ---\n",
            "Época   0 | Loss: 0.2247 | Acurácia: 50.00%\n",
            "Época  10 | Loss: 0.2111 | Acurácia: 75.00%\n",
            "Época  20 | Loss: 0.2088 | Acurácia: 75.00%\n",
            "Época  30 | Loss: 0.2065 | Acurácia: 75.00%\n",
            "Época  40 | Loss: 0.2043 | Acurácia: 75.00%\n",
            "Época  50 | Loss: 0.2020 | Acurácia: 75.00%\n",
            "Época  60 | Loss: 0.1998 | Acurácia: 75.00%\n",
            "Época  70 | Loss: 0.1976 | Acurácia: 75.00%\n",
            "Época  80 | Loss: 0.1954 | Acurácia: 75.00%\n",
            "Época  90 | Loss: 0.1932 | Acurácia: 75.00%\n",
            "Época  99 | Loss: 0.1912 | Acurácia: 75.00%\n",
            "\n",
            "--- Validação com Dados de Treinamento ---\n",
            "Entrada: [0, 0] | Esperado: 0 | Predição: 0.7612 | Correto: ✗\n",
            "Entrada: [0, 1] | Esperado: 1 | Predição: 0.8124 | Correto: ✓\n",
            "Entrada: [1, 0] | Esperado: 1 | Predição: 0.8219 | Correto: ✓\n",
            "Entrada: [1, 1] | Esperado: 1 | Predição: 0.8609 | Correto: ✓\n",
            "\n",
            "--- Teste de Consistência (rodando predições novamente) ---\n",
            "Entrada: [0, 0] | Predição: 0.7612\n",
            "Entrada: [0, 1] | Predição: 0.8124\n",
            "Entrada: [1, 0] | Predição: 0.8219\n",
            "Entrada: [1, 1] | Predição: 0.8609\n",
            "\n",
            "======================================================================\n",
            "TESTE 2: Rede Neural para Porta Lógica XOR (mais difícil!)\n",
            "======================================================================\n",
            "\n",
            "RedeNeural(2 → 4 → 1)\n",
            "\n",
            "--- Treinamento ---\n",
            "Época   0 | Loss: 0.3262 | Acurácia: 50.00%\n",
            "Época  10 | Loss: 0.3065 | Acurácia: 50.00%\n",
            "Época  20 | Loss: 0.3066 | Acurácia: 50.00%\n",
            "Época  30 | Loss: 0.3067 | Acurácia: 50.00%\n",
            "Época  40 | Loss: 0.3067 | Acurácia: 50.00%\n",
            "Época  50 | Loss: 0.3068 | Acurácia: 50.00%\n",
            "Época  60 | Loss: 0.3069 | Acurácia: 50.00%\n",
            "Época  70 | Loss: 0.3070 | Acurácia: 50.00%\n",
            "Época  80 | Loss: 0.3070 | Acurácia: 50.00%\n",
            "Época  90 | Loss: 0.3071 | Acurácia: 50.00%\n",
            "Época 100 | Loss: 0.3072 | Acurácia: 50.00%\n",
            "Época 110 | Loss: 0.3072 | Acurácia: 50.00%\n",
            "Época 120 | Loss: 0.3073 | Acurácia: 50.00%\n",
            "Época 130 | Loss: 0.3074 | Acurácia: 50.00%\n",
            "Época 140 | Loss: 0.3074 | Acurácia: 50.00%\n",
            "Época 150 | Loss: 0.3075 | Acurácia: 50.00%\n",
            "Época 160 | Loss: 0.3075 | Acurácia: 50.00%\n",
            "Época 170 | Loss: 0.3076 | Acurácia: 50.00%\n",
            "Época 180 | Loss: 0.3076 | Acurácia: 50.00%\n",
            "Época 190 | Loss: 0.3077 | Acurácia: 50.00%\n",
            "Época 200 | Loss: 0.3077 | Acurácia: 50.00%\n",
            "Época 210 | Loss: 0.3077 | Acurácia: 50.00%\n",
            "Época 220 | Loss: 0.3078 | Acurácia: 50.00%\n",
            "Época 230 | Loss: 0.3078 | Acurácia: 50.00%\n",
            "Época 240 | Loss: 0.3078 | Acurácia: 50.00%\n",
            "Época 250 | Loss: 0.3079 | Acurácia: 50.00%\n",
            "Época 260 | Loss: 0.3079 | Acurácia: 50.00%\n",
            "Época 270 | Loss: 0.3079 | Acurácia: 50.00%\n",
            "Época 280 | Loss: 0.3079 | Acurácia: 50.00%\n",
            "Época 290 | Loss: 0.3080 | Acurácia: 50.00%\n",
            "Época 300 | Loss: 0.3080 | Acurácia: 25.00%\n",
            "Época 310 | Loss: 0.3080 | Acurácia: 25.00%\n",
            "Época 320 | Loss: 0.3080 | Acurácia: 25.00%\n",
            "Época 330 | Loss: 0.3080 | Acurácia: 25.00%\n",
            "Época 340 | Loss: 0.3080 | Acurácia: 25.00%\n",
            "Época 350 | Loss: 0.3080 | Acurácia: 25.00%\n",
            "Época 360 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 370 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 380 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 390 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 400 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 410 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 420 | Loss: 0.3081 | Acurácia: 25.00%\n",
            "Época 430 | Loss: 0.3081 | Acurácia: 0.00%\n",
            "Época 440 | Loss: 0.3081 | Acurácia: 0.00%\n",
            "Época 450 | Loss: 0.3081 | Acurácia: 0.00%\n",
            "Época 460 | Loss: 0.3081 | Acurácia: 0.00%\n",
            "Época 470 | Loss: 0.3081 | Acurácia: 0.00%\n",
            "Época 480 | Loss: 0.3081 | Acurácia: 0.00%\n",
            "Época 490 | Loss: 0.3080 | Acurácia: 0.00%\n",
            "Época 499 | Loss: 0.3080 | Acurácia: 0.00%\n",
            "\n",
            "--- Validação XOR ---\n",
            "Entrada: [0, 0] | Esperado: 0 | Predição: 0.5018 | ✗\n",
            "Entrada: [0, 1] | Esperado: 1 | Predição: 0.4788 | ✗\n",
            "Entrada: [1, 0] | Esperado: 1 | Predição: 0.4637 | ✗\n",
            "Entrada: [1, 1] | Esperado: 0 | Predição: 0.4437 | ✓\n",
            "\n",
            "======================================================================\n",
            "TESTE 3: Classificação Multi-Classe (3 classes)\n",
            "======================================================================\n",
            "\n",
            "RedeNeural(5 → 8 → 3)\n",
            "\n",
            "--- Treinamento ---\n",
            "Época   0 | Loss: 0.3974 | Acurácia: 33.33%\n",
            "Época  10 | Loss: 0.2422 | Acurácia: 33.33%\n",
            "Época  20 | Loss: 0.2307 | Acurácia: 33.33%\n",
            "Época  30 | Loss: 0.2201 | Acurácia: 44.44%\n",
            "Época  40 | Loss: 0.2103 | Acurácia: 44.44%\n",
            "Época  50 | Loss: 0.2012 | Acurácia: 55.56%\n",
            "Época  60 | Loss: 0.1927 | Acurácia: 55.56%\n",
            "Época  70 | Loss: 0.1848 | Acurácia: 55.56%\n",
            "Época  80 | Loss: 0.1775 | Acurácia: 66.67%\n",
            "Época  90 | Loss: 0.1706 | Acurácia: 66.67%\n",
            "Época 100 | Loss: 0.1643 | Acurácia: 66.67%\n",
            "Época 110 | Loss: 0.1583 | Acurácia: 66.67%\n",
            "Época 120 | Loss: 0.1527 | Acurácia: 66.67%\n",
            "Época 130 | Loss: 0.1475 | Acurácia: 66.67%\n",
            "Época 140 | Loss: 0.1426 | Acurácia: 88.89%\n",
            "Época 150 | Loss: 0.1380 | Acurácia: 88.89%\n",
            "Época 160 | Loss: 0.1337 | Acurácia: 88.89%\n",
            "Época 170 | Loss: 0.1296 | Acurácia: 88.89%\n",
            "Época 180 | Loss: 0.1257 | Acurácia: 88.89%\n",
            "Época 190 | Loss: 0.1220 | Acurácia: 100.00%\n",
            "Época 199 | Loss: 0.1189 | Acurácia: 100.00%\n",
            "\n",
            "--- Validação Multi-Classe ---\n",
            "Exemplo 1 | Entrada: [1, 0, 0, 0, 0]\n",
            "  Esperado: Classe 0 [1, 0, 0]\n",
            "  Predito:  Classe 0 [0.555 0.281 0.142] ✓\n",
            "Exemplo 2 | Entrada: [1, 1, 0, 0, 0]\n",
            "  Esperado: Classe 0 [1, 0, 0]\n",
            "  Predito:  Classe 1 [0.492 0.498 0.076] ✗\n",
            "Exemplo 3 | Entrada: [1, 0, 1, 0, 0]\n",
            "  Esperado: Classe 0 [1, 0, 0]\n",
            "  Predito:  Classe 2 [0.306 0.2   0.415] ✗\n",
            "Exemplo 4 | Entrada: [0, 1, 0, 0, 0]\n",
            "  Esperado: Classe 1 [0, 1, 0]\n",
            "  Predito:  Classe 1 [0.173 0.63  0.191] ✓\n",
            "Exemplo 5 | Entrada: [0, 1, 1, 0, 0]\n",
            "  Esperado: Classe 1 [0, 1, 0]\n",
            "  Predito:  Classe 2 [0.108 0.415 0.482] ✗\n",
            "Exemplo 6 | Entrada: [0, 1, 0, 1, 0]\n",
            "  Esperado: Classe 1 [0, 1, 0]\n",
            "  Predito:  Classe 1 [0.19  0.456 0.272] ✓\n",
            "Exemplo 7 | Entrada: [0, 0, 1, 0, 0]\n",
            "  Esperado: Classe 2 [0, 0, 1]\n",
            "  Predito:  Classe 2 [0.082 0.224 0.765] ✓\n",
            "Exemplo 8 | Entrada: [0, 0, 1, 1, 0]\n",
            "  Esperado: Classe 2 [0, 0, 1]\n",
            "  Predito:  Classe 2 [0.106 0.18  0.739] ✓\n",
            "Exemplo 9 | Entrada: [0, 0, 1, 0, 1]\n",
            "  Esperado: Classe 2 [0, 0, 1]\n",
            "  Predito:  Classe 2 [0.099 0.159 0.807] ✓\n",
            "\n",
            "--- Teste com Dados NOVOS (Generalização) ---\n",
            "Entrada NOVA 1: [1, 1, 1, 0, 0]\n",
            "  Predição: Classe 1 [0.274 0.353 0.267]\n",
            "Entrada NOVA 2: [0, 1, 1, 1, 0]\n",
            "  Predição: Classe 2 [0.132 0.323 0.499]\n",
            "Entrada NOVA 3: [0, 0, 1, 1, 1]\n",
            "  Predição: Classe 2 [0.122 0.146 0.764]\n",
            "\n",
            "======================================================================\n",
            "TESTE 4: Visualização do Histórico de Treinamento\n",
            "======================================================================\n",
            "\n",
            "--- Evolução do Loss (OR) ---\n",
            "Época   0: Loss = 0.224743\n",
            "Época  25: Loss = 0.207677\n",
            "Época  50: Loss = 0.202047\n",
            "Época  75: Loss = 0.196494\n",
            "Época  99: Loss = 0.191247\n",
            "\n",
            "--- Evolução da Acurácia (XOR) ---\n",
            "Época   0: Acurácia = 50.00%\n",
            "Época 100: Acurácia = 50.00%\n",
            "Época 200: Acurácia = 50.00%\n",
            "Época 300: Acurácia = 25.00%\n",
            "Época 400: Acurácia = 25.00%\n",
            "Época 499: Acurácia = 0.00%\n"
          ]
        }
      ]
    }
  ]
}